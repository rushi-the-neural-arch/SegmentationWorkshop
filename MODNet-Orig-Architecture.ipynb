{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from mobilenetv2 import MobileNetV2\n",
    "\n",
    "\n",
    "class BaseBackbone(nn.Module):\n",
    "    \"\"\" Superclass of Replaceable Backbone Model for Semantic Estimation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(BaseBackbone, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.model = None\n",
    "        self.enc_channels = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_pretrained_ckpt(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MobileNetV2Backbone(BaseBackbone):\n",
    "    \"\"\" MobileNetV2 Backbone \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(MobileNetV2Backbone, self).__init__(in_channels)\n",
    "\n",
    "        self.model = MobileNetV2(self.in_channels, alpha=1.0, expansion=6, num_classes=None)\n",
    "        \n",
    "        self.enc_channels = [16, 24, 32, 96, 1280]       ####################### ENCODER CHANNELS #######################\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(0, 2)), x)\n",
    "        x = self.model.features[0](x)\n",
    "        x = self.model.features[1](x)\n",
    "        enc2x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(2, 4)), x)\n",
    "        x = self.model.features[2](x)\n",
    "        x = self.model.features[3](x)\n",
    "        enc4x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(4, 7)), x)\n",
    "        x = self.model.features[4](x)\n",
    "        x = self.model.features[5](x)\n",
    "        x = self.model.features[6](x)\n",
    "        enc8x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(7, 14)), x)\n",
    "        x = self.model.features[7](x)\n",
    "        x = self.model.features[8](x)\n",
    "        x = self.model.features[9](x)\n",
    "        x = self.model.features[10](x)\n",
    "        x = self.model.features[11](x)\n",
    "        x = self.model.features[12](x)\n",
    "        x = self.model.features[13](x)\n",
    "        enc16x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(14, 19)), x)\n",
    "        x = self.model.features[14](x)\n",
    "        x = self.model.features[15](x)\n",
    "        x = self.model.features[16](x)\n",
    "        x = self.model.features[17](x)\n",
    "        x = self.model.features[18](x)\n",
    "        enc32x = x\n",
    "        \n",
    "        return [enc2x, enc4x, enc8x, enc16x, enc32x]\n",
    "\n",
    "    def load_pretrained_ckpt(self):\n",
    "        # the pre-trained model is provided by https://github.com/thuyngch/Human-Segmentation-PyTorch \n",
    "        ckpt_path = './pretrained/mobilenetv2_human_seg.ckpt'\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            print('cannot find the pretrained mobilenetv2 backbone')\n",
    "            exit()\n",
    "        \n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        self.model.load_state_dict(ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBNorm(nn.Module):\n",
    "    \"\"\" Combine Instance Norm and Batch Norm into One Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(IBNorm, self).__init__()\n",
    "        in_channels = in_channels\n",
    "        self.bnorm_channels = int(in_channels / 2)\n",
    "        self.inorm_channels = in_channels - self.bnorm_channels\n",
    "\n",
    "        self.bnorm = nn.BatchNorm2d(self.bnorm_channels, affine=True)\n",
    "        self.inorm = nn.InstanceNorm2d(self.inorm_channels, affine=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bn_x = self.bnorm(x[:, :self.bnorm_channels, ...].contiguous())\n",
    "        in_x = self.inorm(x[:, self.bnorm_channels:, ...].contiguous())\n",
    "\n",
    "        return torch.cat((bn_x, in_x), 1)\n",
    "\n",
    "class Conv2dIBNormRelu(nn.Module):\n",
    "    \"\"\" Convolution + IBNorm + ReLu\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                 with_ibn=True, with_relu=True):\n",
    "        super(Conv2dIBNormRelu, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "                      stride=stride, padding=padding, dilation=dilation, \n",
    "                      groups=groups, bias=bias)\n",
    "        ]\n",
    "\n",
    "        if with_ibn:       \n",
    "            layers.append(IBNorm(out_channels))\n",
    "        if with_relu:\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x) \n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\" SE Block Proposed in https://arxiv.org/pdf/1709.01507.pdf \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, reduction=1):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, int(in_channels // reduction), bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(in_channels // reduction), out_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        w = self.pool(x).view(b, c)\n",
    "        w = self.fc(w).view(b, c, 1, 1)\n",
    "\n",
    "        return x * w.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_BACKBONES = {\n",
    "    'mobilenetv2': MobileNetV2Backbone,\n",
    "}\n",
    "\n",
    "class LRBranch(nn.Module):\n",
    "    \"\"\" Low Resolution Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone):\n",
    "        super(LRBranch, self).__init__()\n",
    "\n",
    "        enc_channels = backbone.enc_channels\n",
    "        \n",
    "        print(\"---------\", enc_channels)\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.se_block = SEBlock(enc_channels[4], enc_channels[4], reduction=4)\n",
    "        self.conv_lr16x = Conv2dIBNormRelu(enc_channels[4], enc_channels[3], 5, stride=1, padding=2)\n",
    "        self.conv_lr8x = Conv2dIBNormRelu(enc_channels[3], enc_channels[2], 5, stride=1, padding=2)\n",
    "        self.conv_lr = Conv2dIBNormRelu(enc_channels[2], 1, kernel_size=3, stride=2, padding=1, with_ibn=False, with_relu=False)\n",
    "\n",
    "    def forward(self, img, inference=False):\n",
    "        enc_features = self.backbone.forward(img)\n",
    "        enc2x, enc4x, enc32x = enc_features[0], enc_features[1], enc_features[4]\n",
    "\n",
    "        enc32x = self.se_block(enc32x)\n",
    "        lr16x = F.interpolate(enc32x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr16x = self.conv_lr16x(lr16x)\n",
    "        lr8x = F.interpolate(lr16x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr8x = self.conv_lr8x(lr8x)\n",
    "\n",
    "        pred_semantic = None\n",
    "        if not inference:\n",
    "            lr = self.conv_lr(lr8x)\n",
    "            pred_semantic = torch.sigmoid(lr)\n",
    "        \n",
    "        return pred_semantic, lr8x, [enc2x, enc4x] \n",
    "    \n",
    "\n",
    "class HRBranch(nn.Module):\n",
    "    \"\"\" High Resolution Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_channels, enc_channels):\n",
    "        super(HRBranch, self).__init__()\n",
    "\n",
    "        self.tohr_enc2x = Conv2dIBNormRelu(enc_channels[0], hr_channels, 1, stride=1, padding=0)\n",
    "        self.conv_enc2x = Conv2dIBNormRelu(hr_channels + 3, hr_channels, 3, stride=2, padding=1)\n",
    "\n",
    "        self.tohr_enc4x = Conv2dIBNormRelu(enc_channels[1], hr_channels, 1, stride=1, padding=0)\n",
    "        self.conv_enc4x = Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1)\n",
    "\n",
    "        self.conv_hr4x = nn.Sequential(\n",
    "            Conv2dIBNormRelu(3 * hr_channels + 3, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_hr2x = nn.Sequential(\n",
    "            Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_hr = nn.Sequential(\n",
    "            Conv2dIBNormRelu(hr_channels + 3, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, 1, kernel_size=1, stride=1, padding=0, with_ibn=False, with_relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, enc2x, enc4x, lr8x, inference):\n",
    "        img2x = F.interpolate(img, scale_factor=1/2, mode='bilinear', align_corners=False)\n",
    "        img4x = F.interpolate(img, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "\n",
    "        enc2x = self.tohr_enc2x(enc2x)\n",
    "        hr4x = self.conv_enc2x(torch.cat((img2x, enc2x), dim=1))\n",
    "\n",
    "        enc4x = self.tohr_enc4x(enc4x)\n",
    "        hr4x = self.conv_enc4x(torch.cat((hr4x, enc4x), dim=1))\n",
    "\n",
    "        lr4x = F.interpolate(lr8x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        hr4x = self.conv_hr4x(torch.cat((hr4x, lr4x, img4x), dim=1))\n",
    "\n",
    "        hr2x = F.interpolate(hr4x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        hr2x = self.conv_hr2x(torch.cat((hr2x, enc2x), dim=1))\n",
    "\n",
    "        pred_detail = None\n",
    "        if not inference:\n",
    "            hr = F.interpolate(hr2x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            hr = self.conv_hr(torch.cat((hr, img), dim=1))\n",
    "            pred_detail = torch.sigmoid(hr)\n",
    "\n",
    "        return pred_detail, hr2x\n",
    "\n",
    "\n",
    "class FusionBranch(nn.Module):\n",
    "    \"\"\" Fusion Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_channels, enc_channels):\n",
    "        super(FusionBranch, self).__init__()\n",
    "        self.conv_lr4x = Conv2dIBNormRelu(enc_channels[2], hr_channels, 5, stride=1, padding=2)\n",
    "        \n",
    "        self.conv_f2x = Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1)\n",
    "        self.conv_f = nn.Sequential(\n",
    "            Conv2dIBNormRelu(hr_channels + 3, int(hr_channels / 2), 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(int(hr_channels / 2), 1, 1, stride=1, padding=0, with_ibn=False, with_relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, lr8x, hr2x):\n",
    "        lr4x = F.interpolate(lr8x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr4x = self.conv_lr4x(lr4x)\n",
    "        lr2x = F.interpolate(lr4x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        f2x = self.conv_f2x(torch.cat((lr2x, hr2x), dim=1))\n",
    "        f = F.interpolate(f2x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        f = self.conv_f(torch.cat((f, img), dim=1))\n",
    "        #pred_matte = torch.sigmoid(f)\n",
    "\n",
    "        #return pred_matte\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#  MODNet\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class MODNet(nn.Module):\n",
    "    \"\"\" Architecture of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, hr_channels=32, backbone_arch='mobilenetv2', backbone_pretrained=False):\n",
    "        super(MODNet, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hr_channels = hr_channels\n",
    "        self.backbone_arch = backbone_arch \n",
    "        self.backbone_pretrained = backbone_pretrained\n",
    "\n",
    "        self.backbone = SUPPORTED_BACKBONES[self.backbone_arch](self.in_channels)\n",
    "\n",
    "        self.lr_branch = LRBranch(self.backbone)\n",
    "        self.hr_branch = HRBranch(self.hr_channels, self.backbone.enc_channels)\n",
    "        self.f_branch = FusionBranch(self.hr_channels, self.backbone.enc_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                self._init_conv(m)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
    "                self._init_norm(m)\n",
    "\n",
    "        if self.backbone_pretrained:\n",
    "            self.backbone.load_pretrained_ckpt()                \n",
    "\n",
    "    def forward(self, img, inference=False):\n",
    "        pred_semantic, lr8x, [enc2x, enc4x] = self.lr_branch(img, inference)\n",
    "        pred_detail, hr2x = self.hr_branch(img, enc2x, enc4x, lr8x, inference)\n",
    "        pred_matte = self.f_branch(img, lr8x, hr2x)\n",
    "\n",
    "        return pred_semantic, pred_detail, pred_matte\n",
    "    \n",
    "    def freeze_norm(self):\n",
    "        norm_types = [nn.BatchNorm2d, nn.InstanceNorm2d]\n",
    "        for m in self.modules():\n",
    "            for n in norm_types:\n",
    "                if isinstance(m, n):\n",
    "                    m.eval()\n",
    "                    continue\n",
    "\n",
    "    def _init_conv(self, conv):\n",
    "        nn.init.kaiming_uniform_(\n",
    "            conv.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        if conv.bias is not None:\n",
    "            nn.init.constant_(conv.bias, 0)\n",
    "\n",
    "    def _init_norm(self, norm):\n",
    "        if norm.weight is not None:\n",
    "            nn.init.constant_(norm.weight, 1)\n",
    "            nn.init.constant_(norm.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- [16, 24, 32, 96, 1280]\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─LRBranch: 1-1                               [-1, 1, 14, 14]           --\n",
      "|    └─SEBlock: 2-1                           [-1, 1280, 7, 7]          --\n",
      "|    |    └─AdaptiveAvgPool2d: 3-1            [-1, 1280, 1, 1]          --\n",
      "|    |    └─Sequential: 3-2                   [-1, 1280]                819,200\n",
      "|    └─Conv2dIBNormRelu: 2-2                  [-1, 96, 14, 14]          --\n",
      "|    |    └─Sequential: 3-3                   [-1, 96, 14, 14]          3,072,192\n",
      "|    └─Conv2dIBNormRelu: 2-3                  [-1, 32, 28, 28]          --\n",
      "|    |    └─Sequential: 3-4                   [-1, 32, 28, 28]          76,864\n",
      "|    └─Conv2dIBNormRelu: 2-4                  [-1, 1, 14, 14]           --\n",
      "|    |    └─Sequential: 3-5                   [-1, 1, 14, 14]           289\n",
      "├─HRBranch: 1-2                               [-1, 1, 224, 224]         --\n",
      "|    └─Conv2dIBNormRelu: 2-5                  [-1, 32, 112, 112]        --\n",
      "|    |    └─Sequential: 3-6                   [-1, 32, 112, 112]        576\n",
      "|    └─Conv2dIBNormRelu: 2-6                  [-1, 32, 56, 56]          --\n",
      "|    |    └─Sequential: 3-7                   [-1, 32, 56, 56]          10,144\n",
      "|    └─Conv2dIBNormRelu: 2-7                  [-1, 32, 56, 56]          --\n",
      "|    |    └─Sequential: 3-8                   [-1, 32, 56, 56]          832\n",
      "|    └─Conv2dIBNormRelu: 2-8                  [-1, 64, 56, 56]          --\n",
      "|    |    └─Sequential: 3-9                   [-1, 64, 56, 56]          36,992\n",
      "|    └─Sequential: 2-9                        [-1, 32, 56, 56]          --\n",
      "|    |    └─Conv2dIBNormRelu: 3-10            [-1, 64, 56, 56]          57,152\n",
      "|    |    └─Conv2dIBNormRelu: 3-11            [-1, 64, 56, 56]          36,992\n",
      "|    |    └─Conv2dIBNormRelu: 3-12            [-1, 32, 56, 56]          18,496\n",
      "|    └─Sequential: 2-10                       [-1, 32, 112, 112]        --\n",
      "|    |    └─Conv2dIBNormRelu: 3-13            [-1, 64, 112, 112]        36,992\n",
      "|    |    └─Conv2dIBNormRelu: 3-14            [-1, 32, 112, 112]        18,496\n",
      "|    |    └─Conv2dIBNormRelu: 3-15            [-1, 32, 112, 112]        9,280\n",
      "|    |    └─Conv2dIBNormRelu: 3-16            [-1, 32, 112, 112]        9,280\n",
      "|    └─Sequential: 2-11                       [-1, 1, 224, 224]         --\n",
      "|    |    └─Conv2dIBNormRelu: 3-17            [-1, 32, 224, 224]        10,144\n",
      "|    |    └─Conv2dIBNormRelu: 3-18            [-1, 1, 224, 224]         33\n",
      "├─FusionBranch: 1-3                           [-1, 1, 224, 224]         --\n",
      "|    └─Conv2dIBNormRelu: 2-12                 [-1, 32, 56, 56]          --\n",
      "|    |    └─Sequential: 3-19                  [-1, 32, 56, 56]          25,664\n",
      "|    └─Conv2dIBNormRelu: 2-13                 [-1, 32, 112, 112]        --\n",
      "|    |    └─Sequential: 3-20                  [-1, 32, 112, 112]        18,496\n",
      "|    └─Sequential: 2-14                       [-1, 1, 224, 224]         --\n",
      "|    |    └─Conv2dIBNormRelu: 3-21            [-1, 16, 224, 224]        5,072\n",
      "|    |    └─Conv2dIBNormRelu: 3-22            [-1, 1, 224, 224]         17\n",
      "===============================================================================================\n",
      "Total params: 4,263,203\n",
      "Trainable params: 4,263,203\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.15\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 10.30\n",
      "Params size (MB): 16.26\n",
      "Estimated Total Size (MB): 27.14\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─LRBranch: 1-1                               [-1, 1, 14, 14]           --\n",
       "|    └─SEBlock: 2-1                           [-1, 1280, 7, 7]          --\n",
       "|    |    └─AdaptiveAvgPool2d: 3-1            [-1, 1280, 1, 1]          --\n",
       "|    |    └─Sequential: 3-2                   [-1, 1280]                819,200\n",
       "|    └─Conv2dIBNormRelu: 2-2                  [-1, 96, 14, 14]          --\n",
       "|    |    └─Sequential: 3-3                   [-1, 96, 14, 14]          3,072,192\n",
       "|    └─Conv2dIBNormRelu: 2-3                  [-1, 32, 28, 28]          --\n",
       "|    |    └─Sequential: 3-4                   [-1, 32, 28, 28]          76,864\n",
       "|    └─Conv2dIBNormRelu: 2-4                  [-1, 1, 14, 14]           --\n",
       "|    |    └─Sequential: 3-5                   [-1, 1, 14, 14]           289\n",
       "├─HRBranch: 1-2                               [-1, 1, 224, 224]         --\n",
       "|    └─Conv2dIBNormRelu: 2-5                  [-1, 32, 112, 112]        --\n",
       "|    |    └─Sequential: 3-6                   [-1, 32, 112, 112]        576\n",
       "|    └─Conv2dIBNormRelu: 2-6                  [-1, 32, 56, 56]          --\n",
       "|    |    └─Sequential: 3-7                   [-1, 32, 56, 56]          10,144\n",
       "|    └─Conv2dIBNormRelu: 2-7                  [-1, 32, 56, 56]          --\n",
       "|    |    └─Sequential: 3-8                   [-1, 32, 56, 56]          832\n",
       "|    └─Conv2dIBNormRelu: 2-8                  [-1, 64, 56, 56]          --\n",
       "|    |    └─Sequential: 3-9                   [-1, 64, 56, 56]          36,992\n",
       "|    └─Sequential: 2-9                        [-1, 32, 56, 56]          --\n",
       "|    |    └─Conv2dIBNormRelu: 3-10            [-1, 64, 56, 56]          57,152\n",
       "|    |    └─Conv2dIBNormRelu: 3-11            [-1, 64, 56, 56]          36,992\n",
       "|    |    └─Conv2dIBNormRelu: 3-12            [-1, 32, 56, 56]          18,496\n",
       "|    └─Sequential: 2-10                       [-1, 32, 112, 112]        --\n",
       "|    |    └─Conv2dIBNormRelu: 3-13            [-1, 64, 112, 112]        36,992\n",
       "|    |    └─Conv2dIBNormRelu: 3-14            [-1, 32, 112, 112]        18,496\n",
       "|    |    └─Conv2dIBNormRelu: 3-15            [-1, 32, 112, 112]        9,280\n",
       "|    |    └─Conv2dIBNormRelu: 3-16            [-1, 32, 112, 112]        9,280\n",
       "|    └─Sequential: 2-11                       [-1, 1, 224, 224]         --\n",
       "|    |    └─Conv2dIBNormRelu: 3-17            [-1, 32, 224, 224]        10,144\n",
       "|    |    └─Conv2dIBNormRelu: 3-18            [-1, 1, 224, 224]         33\n",
       "├─FusionBranch: 1-3                           [-1, 1, 224, 224]         --\n",
       "|    └─Conv2dIBNormRelu: 2-12                 [-1, 32, 56, 56]          --\n",
       "|    |    └─Sequential: 3-19                  [-1, 32, 56, 56]          25,664\n",
       "|    └─Conv2dIBNormRelu: 2-13                 [-1, 32, 112, 112]        --\n",
       "|    |    └─Sequential: 3-20                  [-1, 32, 112, 112]        18,496\n",
       "|    └─Sequential: 2-14                       [-1, 1, 224, 224]         --\n",
       "|    |    └─Conv2dIBNormRelu: 3-21            [-1, 16, 224, 224]        5,072\n",
       "|    |    └─Conv2dIBNormRelu: 3-22            [-1, 1, 224, 224]         17\n",
       "===============================================================================================\n",
       "Total params: 4,263,203\n",
       "Trainable params: 4,263,203\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.15\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 10.30\n",
       "Params size (MB): 16.26\n",
       "Estimated Total Size (MB): 27.14\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = MODNet()\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting each branch and trying a lighter alernative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_BACKBONES = {\n",
    "    'mobilenetv2': MobileNetV2Backbone,\n",
    "}\n",
    "\n",
    "class LRBranch(nn.Module):\n",
    "    \"\"\" Low Resolution Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone):\n",
    "        super(LRBranch, self).__init__()\n",
    "\n",
    "        enc_channels = backbone.enc_channels\n",
    "        \n",
    "        print(\"---------\", enc_channels)\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.se_block = SEBlock(enc_channels[3], enc_channels[3], reduction=4) # enc_channels[4]\n",
    "        self.conv_lr16x = Conv2dIBNormRelu(enc_channels[3], enc_channels[2], 5, stride=1, padding=2) # enc_channels[4],  enc_channels[3]\n",
    "        self.conv_lr8x = Conv2dIBNormRelu(enc_channels[2], enc_channels[2], 5, stride=1, padding=2) # enc_channels[3]\n",
    "        self.conv_lr = Conv2dIBNormRelu(enc_channels[2], 1, kernel_size=3, stride=2, padding=1, with_ibn=False, with_relu=False)\n",
    "\n",
    "    def forward(self, img, inference=False):\n",
    "        enc_features = self.backbone.forward(img)\n",
    "        enc2x, enc4x, enc32x = enc_features[0], enc_features[1], enc_features[3] # enc_features[3]\n",
    "\n",
    "        enc32x = self.se_block(enc32x)\n",
    "        lr16x = F.interpolate(enc32x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr16x = self.conv_lr16x(lr16x)\n",
    "        lr8x = F.interpolate(lr16x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr8x = self.conv_lr8x(lr8x)\n",
    "\n",
    "        pred_semantic = None\n",
    "        if not inference:\n",
    "            lr = self.conv_lr(lr8x)\n",
    "            pred_semantic = torch.sigmoid(lr)\n",
    "        \n",
    "        return pred_semantic, lr8x, [enc2x, enc4x] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- [16, 24, 32, 96, 1280]\n"
     ]
    }
   ],
   "source": [
    "in_channels=3\n",
    "hr_channels=32\n",
    "backbone_arch='mobilenetv2'\n",
    "backbone_pretrained=False\n",
    "\n",
    "backbone = SUPPORTED_BACKBONES[backbone_arch](in_channels)\n",
    "\n",
    "lr_branch = LRBranch(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─SEBlock: 1-1                                [-1, 96, 14, 14]          --\n",
      "|    └─AdaptiveAvgPool2d: 2-1                 [-1, 96, 1, 1]            --\n",
      "|    └─Sequential: 2-2                        [-1, 96]                  --\n",
      "|    |    └─Linear: 3-1                       [-1, 24]                  2,304\n",
      "|    |    └─ReLU: 3-2                         [-1, 24]                  --\n",
      "|    |    └─Linear: 3-3                       [-1, 96]                  2,304\n",
      "|    |    └─Sigmoid: 3-4                      [-1, 96]                  --\n",
      "├─Conv2dIBNormRelu: 1-2                       [-1, 32, 28, 28]          --\n",
      "|    └─Sequential: 2-3                        [-1, 32, 28, 28]          --\n",
      "|    |    └─Conv2d: 3-5                       [-1, 32, 28, 28]          76,832\n",
      "|    |    └─IBNorm: 3-6                       [-1, 32, 28, 28]          32\n",
      "|    |    └─ReLU: 3-7                         [-1, 32, 28, 28]          --\n",
      "├─Conv2dIBNormRelu: 1-3                       [-1, 32, 56, 56]          --\n",
      "|    └─Sequential: 2-4                        [-1, 32, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-8                       [-1, 32, 56, 56]          25,632\n",
      "|    |    └─IBNorm: 3-9                       [-1, 32, 56, 56]          32\n",
      "|    |    └─ReLU: 3-10                        [-1, 32, 56, 56]          --\n",
      "├─Conv2dIBNormRelu: 1-4                       [-1, 1, 28, 28]           --\n",
      "|    └─Sequential: 2-5                        [-1, 1, 28, 28]           --\n",
      "|    |    └─Conv2d: 3-11                      [-1, 1, 28, 28]           289\n",
      "===============================================================================================\n",
      "Total params: 107,425\n",
      "Trainable params: 107,425\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 143.14\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1.44\n",
      "Params size (MB): 0.41\n",
      "Estimated Total Size (MB): 2.43\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─SEBlock: 1-1                                [-1, 96, 14, 14]          --\n",
       "|    └─AdaptiveAvgPool2d: 2-1                 [-1, 96, 1, 1]            --\n",
       "|    └─Sequential: 2-2                        [-1, 96]                  --\n",
       "|    |    └─Linear: 3-1                       [-1, 24]                  2,304\n",
       "|    |    └─ReLU: 3-2                         [-1, 24]                  --\n",
       "|    |    └─Linear: 3-3                       [-1, 96]                  2,304\n",
       "|    |    └─Sigmoid: 3-4                      [-1, 96]                  --\n",
       "├─Conv2dIBNormRelu: 1-2                       [-1, 32, 28, 28]          --\n",
       "|    └─Sequential: 2-3                        [-1, 32, 28, 28]          --\n",
       "|    |    └─Conv2d: 3-5                       [-1, 32, 28, 28]          76,832\n",
       "|    |    └─IBNorm: 3-6                       [-1, 32, 28, 28]          32\n",
       "|    |    └─ReLU: 3-7                         [-1, 32, 28, 28]          --\n",
       "├─Conv2dIBNormRelu: 1-3                       [-1, 32, 56, 56]          --\n",
       "|    └─Sequential: 2-4                        [-1, 32, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-8                       [-1, 32, 56, 56]          25,632\n",
       "|    |    └─IBNorm: 3-9                       [-1, 32, 56, 56]          32\n",
       "|    |    └─ReLU: 3-10                        [-1, 32, 56, 56]          --\n",
       "├─Conv2dIBNormRelu: 1-4                       [-1, 1, 28, 28]           --\n",
       "|    └─Sequential: 2-5                        [-1, 1, 28, 28]           --\n",
       "|    |    └─Conv2d: 3-11                      [-1, 1, 28, 28]           289\n",
       "===============================================================================================\n",
       "Total params: 107,425\n",
       "Trainable params: 107,425\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 143.14\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 1.44\n",
       "Params size (MB): 0.41\n",
       "Estimated Total Size (MB): 2.43\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(lr_branch, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############################ OBSERVATIONS ############################\n",
    "\n",
    "- Just reducing the channels helps largely! (from 1280 to 96 !)\n",
    "- This LR BRanch contributes to ~85% of total parameters in MODNet so trying to make it lightweight will make the entire network small               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR Branch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NOTE - Same as the original version of HRBRanch, just need to take care of interpolation due to shape mismatch because of using fewer channels in the LRBranch. (takes input from the LRBranch)\n",
    "\n",
    "# 245,400 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRBranch(nn.Module):\n",
    "    \"\"\" High Resolution Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_channels, enc_channels):\n",
    "        super(HRBranch, self).__init__()\n",
    "\n",
    "        self.tohr_enc2x = Conv2dIBNormRelu(enc_channels[0], hr_channels, 1, stride=1, padding=0)\n",
    "        self.conv_enc2x = Conv2dIBNormRelu(hr_channels + 3, hr_channels, 3, stride=2, padding=1)\n",
    "\n",
    "        self.tohr_enc4x = Conv2dIBNormRelu(enc_channels[1], hr_channels, 1, stride=1, padding=0)\n",
    "        self.conv_enc4x = Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1)\n",
    "\n",
    "        self.conv_hr4x = nn.Sequential(\n",
    "            Conv2dIBNormRelu(3 * hr_channels + 3, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_hr2x = nn.Sequential(\n",
    "            Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_hr = nn.Sequential(\n",
    "            Conv2dIBNormRelu(hr_channels + 3, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, 1, kernel_size=1, stride=1, padding=0, with_ibn=False, with_relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, enc2x, enc4x, lr8x, inference):\n",
    "        #img2x = F.interpolate(img, scale_factor=1, mode='bilinear', align_corners=False)\n",
    "        #img4x = F.interpolate(img, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "\n",
    "        enc2x = self.tohr_enc2x.cuda()(enc2x)\n",
    "        img2x = F.interpolate(img, scale_factor=1/2, mode='bilinear', align_corners=False)\n",
    "        hr4x = self.conv_enc2x.cuda()(torch.cat((img2x, enc2x), dim=1))\n",
    "\n",
    "        enc4x = self.tohr_enc4x.cuda()(enc4x)\n",
    "        hr4x = self.conv_enc4x.cuda()(torch.cat((hr4x, enc4x), dim=1))\n",
    "\n",
    "        lr4x = F.interpolate(lr8x, scale_factor=1, mode='bilinear', align_corners=False)\n",
    "        img4x = F.interpolate(img, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        print(\"---\", hr4x.shape, lr4x.shape, img4x.shape)\n",
    "        \n",
    "        hr4x = self.conv_hr4x.cuda()(torch.cat((hr4x, lr4x, img4x), dim=1))\n",
    "\n",
    "        hr2x = F.interpolate(hr4x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        hr2x = self.conv_hr2x.cuda()(torch.cat((hr2x, enc2x), dim=1))\n",
    "\n",
    "        pred_detail = None\n",
    "        if not inference:\n",
    "            hr = F.interpolate(hr2x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            hr = self.conv_hr.cuda()(torch.cat((hr, img), dim=1))\n",
    "            pred_detail = torch.sigmoid(hr)\n",
    "\n",
    "        return pred_detail, hr2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_channels=32\n",
    "backbone_arch='mobilenetv2'\n",
    "backbone_pretrained=False\n",
    "\n",
    "backbone = SUPPORTED_BACKBONES[backbone_arch](in_channels)\n",
    "\n",
    "img = torch.randn(1, 3, 224, 224).cuda()\n",
    "pred_semantic, lr8x, [enc2x, enc4x] = lr_branch(img, inference=False)\n",
    "\n",
    "\n",
    "hr_branch = HRBranch(hr_channels, backbone.enc_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - Below Flop, Param counting implementation has been modified for \"HR_Branch\" specifically in \"get_params\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of the PyTorch Models Profiler\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ModelProfiler(nn.Module):\n",
    "    \"\"\" Profile PyTorch models.\n",
    "\n",
    "    Compute FLOPs (FLoating OPerations) and number of trainable parameters of model.\n",
    "\n",
    "    Arguments:\n",
    "        model (nn.Module): model which will be profiled.\n",
    "\n",
    "    Example:\n",
    "        model = torchvision.models.resnet50()\n",
    "        profiler = ModelProfiler(model)\n",
    "        var = torch.zeros(1, 3, 224, 224)\n",
    "        profiler(var)\n",
    "        print(\"FLOPs: {0:.5}; #Params: {1:.5}\".format(profiler.get_flops('G'), profiler.get_params('M')))\n",
    "\n",
    "    Warning:\n",
    "        Model profiler doesn't work with models, wrapped by torch.nn.DataParallel.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.flops = 0\n",
    "        self.units = {'K': 10.**3, 'M': 10.**6, 'G': 10.**9}\n",
    "        self.hooks = None\n",
    "        self._remove_hooks()\n",
    "\n",
    "    def get_flops(self, units='G'):\n",
    "        \"\"\" Get number of floating operations per inference.\n",
    "\n",
    "        Arguments:\n",
    "            units (string): units of the flops value ('K': Kilo (10^3), 'M': Mega (10^6), 'G': Giga (10^9)).\n",
    "\n",
    "        Returns:\n",
    "            Floating operations per inference at the choised units.\n",
    "        \"\"\"\n",
    "        assert units in self.units\n",
    "        return self.flops / self.units[units]\n",
    "\n",
    "    def get_params(self, units='K'):\n",
    "        \"\"\" Get number of trainable parameters of the model.\n",
    "\n",
    "        Arguments:\n",
    "            units (string): units of the flops value ('K': Kilo (10^3), 'M': Mega (10^6), 'G': Giga (10^9)).\n",
    "\n",
    "        Returns:\n",
    "            Number of trainable parameters of the model at the choised units.\n",
    "        \"\"\"\n",
    "        assert units in self.units\n",
    "        model = HRBranch(hr_channels, backbone.enc_channels) # remove this line for general implementation\n",
    "        params = sum(p.numel() for p in model.parameters() if p.requires_grad) # self.model rather than model\n",
    "        if units is not None:\n",
    "            params = params / self.units[units]\n",
    "        return params\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        self.flops = 0\n",
    "        self._init_hooks()\n",
    "        output = self.model(*args, **kwargs)\n",
    "        self._remove_hooks()\n",
    "        return output\n",
    "\n",
    "    def _remove_hooks(self):\n",
    "        if self.hooks is not None:\n",
    "            for hook in self.hooks:\n",
    "                hook.remove()\n",
    "        self.hooks = None\n",
    "\n",
    "    def _init_hooks(self):\n",
    "        self.hooks = []\n",
    "\n",
    "        def hook_compute_flop(module, _, output):\n",
    "            self.flops += module.weight.size()[1:].numel() * output.size()[1:].numel()\n",
    "\n",
    "        def add_hooks(module):\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                self.hooks.append(module.register_forward_hook(hook_compute_flop))\n",
    "\n",
    "        self.model.apply(add_hooks)\n",
    "\n",
    "\n",
    "def profile_model(model, input_size, cuda):\n",
    "    \"\"\" Compute FLOPS and #Params of the CNN.\n",
    "\n",
    "    Arguments:\n",
    "        model (nn.Module): model which should be profiled.\n",
    "        input_size (tuple): size of the input variable.\n",
    "        cuda (bool): if True then variable will be upload to the GPU.\n",
    "\n",
    "    Returns:\n",
    "        dict:\n",
    "            dict[\"flops\"] (float): number of GFLOPs.\n",
    "            dict[\"params\"] (int): number of million parameters.\n",
    "    \"\"\"\n",
    "    profiler = ModelProfiler(model)\n",
    "    var = torch.zeros(input_size)\n",
    "    if cuda:\n",
    "        var = var.cuda()\n",
    "    profiler(var)\n",
    "    return {\"flops\": profiler.get_flops('G'), \"params\": profiler.get_params('M')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- torch.Size([1, 64, 56, 56]) torch.Size([1, 32, 56, 56]) torch.Size([1, 3, 56, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flops': 0.0, 'params': 245.409}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = ModelProfiler(hr_branch(img, enc2x, enc4x, lr8x, False))\n",
    "{\"flops\": profiler.get_flops('G'), \"params\": profiler.get_params('K')} #  # 245,400 params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionBranch(nn.Module):\n",
    "    \"\"\" Fusion Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_channels, enc_channels):\n",
    "        super(FusionBranch, self).__init__()\n",
    "        self.conv_lr4x = Conv2dIBNormRelu(enc_channels[2], hr_channels, 5, stride=1, padding=2)\n",
    "        \n",
    "        self.conv_f2x = Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1)\n",
    "        self.conv_f = nn.Sequential(\n",
    "            Conv2dIBNormRelu(hr_channels + 3, int(hr_channels / 2), 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(int(hr_channels / 2), 1, 1, stride=1, padding=0, with_ibn=False, with_relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, lr8x, hr2x):\n",
    "        lr4x = F.interpolate(lr8x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr4x = self.conv_lr4x.cuda()(lr4x)\n",
    "        lr2x = F.interpolate(lr4x, scale_factor=1, mode='bilinear', align_corners=False)\n",
    "\n",
    "        f2x = self.conv_f2x.cuda()(torch.cat((lr2x, hr2x), dim=1))\n",
    "        f = F.interpolate(f2x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        f = self.conv_f.cuda()(torch.cat((f, img), dim=1))\n",
    "        #pred_matte = torch.sigmoid(f)\n",
    "\n",
    "        #return pred_matte\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- torch.Size([1, 64, 56, 56]) torch.Size([1, 32, 56, 56]) torch.Size([1, 3, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "pred_semantic, lr8x, [enc2x, enc4x] = lr_branch(img, inference=False)\n",
    "pred_detail, hr2x = hr_branch(img, enc2x, enc4x, lr8x, inference=False)\n",
    "\n",
    "hr_channels=32\n",
    "backbone_arch='mobilenetv2'\n",
    "backbone_pretrained=False\n",
    "\n",
    "backbone = SUPPORTED_BACKBONES[backbone_arch](in_channels)\n",
    "\n",
    "f_branch = FusionBranch(hr_channels, backbone.enc_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flops': 0.0, 'params': 245.409}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = ModelProfiler(f_branch(img, lr8x, hr2x))\n",
    "{\"flops\": profiler.get_flops('G'), \"params\": profiler.get_params('K')} #  # 245,400 params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all the sections (modified) together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from backbones.mobilenetv2 import MobileNetV2\n",
    "\n",
    "\n",
    "class BaseBackbone(nn.Module):\n",
    "    \"\"\" Superclass of Replaceable Backbone Model for Semantic Estimation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(BaseBackbone, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.model = None\n",
    "        self.enc_channels = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_pretrained_ckpt(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MobileNetV2Backbone(BaseBackbone):\n",
    "    \"\"\" MobileNetV2 Backbone \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(MobileNetV2Backbone, self).__init__(in_channels)\n",
    "\n",
    "        self.model = MobileNetV2(self.in_channels, alpha=1.0, expansion=6, num_classes=None)\n",
    "        \n",
    "        self.enc_channels = [16, 24, 32, 96, 1280]       ####################### ENCODER CHANNELS #######################\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(0, 2)), x)\n",
    "        x = self.model.features[0](x)\n",
    "        x = self.model.features[1](x)\n",
    "        enc2x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(2, 4)), x)\n",
    "        x = self.model.features[2](x)\n",
    "        x = self.model.features[3](x)\n",
    "        enc4x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(4, 7)), x)\n",
    "        x = self.model.features[4](x)\n",
    "        x = self.model.features[5](x)\n",
    "        x = self.model.features[6](x)\n",
    "        enc8x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(7, 14)), x)\n",
    "        x = self.model.features[7](x)\n",
    "        x = self.model.features[8](x)\n",
    "        x = self.model.features[9](x)\n",
    "        x = self.model.features[10](x)\n",
    "        x = self.model.features[11](x)\n",
    "        x = self.model.features[12](x)\n",
    "        x = self.model.features[13](x)\n",
    "        enc16x = x\n",
    "\n",
    "        # x = reduce(lambda x, n: self.model.features[n](x), list(range(14, 19)), x)\n",
    "        x = self.model.features[14](x)\n",
    "        x = self.model.features[15](x)\n",
    "        x = self.model.features[16](x)\n",
    "        x = self.model.features[17](x)\n",
    "        x = self.model.features[18](x)\n",
    "        enc32x = x\n",
    "        \n",
    "        return [enc2x, enc4x, enc8x, enc16x, enc32x]\n",
    "\n",
    "    def load_pretrained_ckpt(self):\n",
    "        # the pre-trained model is provided by https://github.com/thuyngch/Human-Segmentation-PyTorch \n",
    "        ckpt_path = 'mobilenetv2_human_seg.ckpt' #./pretrained/\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            print('cannot find the pretrained mobilenetv2 backbone')\n",
    "            exit()\n",
    "        \n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        self.model.load_state_dict(ckpt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBNorm(nn.Module):\n",
    "    \"\"\" Combine Instance Norm and Batch Norm into One Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(IBNorm, self).__init__()\n",
    "        in_channels = in_channels\n",
    "        self.bnorm_channels = int(in_channels / 2)\n",
    "        self.inorm_channels = in_channels - self.bnorm_channels\n",
    "\n",
    "        self.bnorm = nn.BatchNorm2d(self.bnorm_channels, affine=True)\n",
    "        self.inorm = nn.InstanceNorm2d(self.inorm_channels, affine=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bn_x = self.bnorm(x[:, :self.bnorm_channels, ...].contiguous())\n",
    "        in_x = self.inorm(x[:, self.bnorm_channels:, ...].contiguous())\n",
    "\n",
    "        return torch.cat((bn_x, in_x), 1)\n",
    "\n",
    "class Conv2dIBNormRelu(nn.Module):\n",
    "    \"\"\" Convolution + IBNorm + ReLu\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                 with_ibn=True, with_relu=True):\n",
    "        super(Conv2dIBNormRelu, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "                      stride=stride, padding=padding, dilation=dilation, \n",
    "                      groups=groups, bias=bias)\n",
    "        ]\n",
    "\n",
    "        if with_ibn:       \n",
    "            layers.append(IBNorm(out_channels))\n",
    "        if with_relu:\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x) \n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\" SE Block Proposed in https://arxiv.org/pdf/1709.01507.pdf \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, reduction=1):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, int(in_channels // reduction), bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(in_channels // reduction), out_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        w = self.pool(x).view(b, c)\n",
    "        w = self.fc(w).view(b, c, 1, 1)\n",
    "\n",
    "        return x * w.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_BACKBONES = {\n",
    "    'mobilenetv2': MobileNetV2Backbone,\n",
    "}\n",
    "\n",
    "class LRBranch(nn.Module):\n",
    "    \"\"\" Low Resolution Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone):\n",
    "        super(LRBranch, self).__init__()\n",
    "\n",
    "        enc_channels = backbone.enc_channels\n",
    "        \n",
    "        print(\"---------\", enc_channels)\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.se_block = SEBlock(enc_channels[3], enc_channels[3], reduction=4) # enc_channels[4]\n",
    "        self.conv_lr16x = Conv2dIBNormRelu(enc_channels[3], enc_channels[2], 5, stride=1, padding=2) # enc_channels[4],  enc_channels[3]\n",
    "        self.conv_lr8x = Conv2dIBNormRelu(enc_channels[2], enc_channels[2], 5, stride=1, padding=2) # enc_channels[3]\n",
    "        self.conv_lr = Conv2dIBNormRelu(enc_channels[2], 1, kernel_size=3, stride=2, padding=1, with_ibn=False, with_relu=False)\n",
    "\n",
    "    def forward(self, img, inference=False):\n",
    "        enc_features = self.backbone.forward(img)\n",
    "        enc2x, enc4x, enc32x = enc_features[0], enc_features[1], enc_features[3] # enc_features[4]\n",
    "\n",
    "        enc32x = self.se_block(enc32x)\n",
    "        lr16x = F.interpolate(enc32x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr16x = self.conv_lr16x(lr16x)\n",
    "        lr8x = F.interpolate(lr16x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr8x = self.conv_lr8x(lr8x)\n",
    "\n",
    "        pred_semantic = None\n",
    "        if not inference:\n",
    "            lr = self.conv_lr(lr8x)\n",
    "            pred_semantic = torch.sigmoid(lr)\n",
    "        \n",
    "        return pred_semantic, lr8x, [enc2x, enc4x] \n",
    "  \n",
    "class HRBranch(nn.Module):\n",
    "    \"\"\" High Resolution Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_channels, enc_channels):\n",
    "        super(HRBranch, self).__init__()\n",
    "\n",
    "        self.tohr_enc2x = Conv2dIBNormRelu(enc_channels[0], hr_channels, 1, stride=1, padding=0)\n",
    "        self.conv_enc2x = Conv2dIBNormRelu(hr_channels + 3, hr_channels, 3, stride=2, padding=1)\n",
    "\n",
    "        self.tohr_enc4x = Conv2dIBNormRelu(enc_channels[1], hr_channels, 1, stride=1, padding=0)\n",
    "        self.conv_enc4x = Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1)\n",
    "\n",
    "        self.conv_hr4x = nn.Sequential(\n",
    "            Conv2dIBNormRelu(3 * hr_channels + 3, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_hr2x = nn.Sequential(\n",
    "            Conv2dIBNormRelu(2 * hr_channels, 2 * hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, hr_channels, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_hr = nn.Sequential(\n",
    "            Conv2dIBNormRelu(hr_channels + 3, hr_channels, 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(hr_channels, 1, kernel_size=1, stride=1, padding=0, with_ibn=False, with_relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, enc2x, enc4x, lr8x, inference):\n",
    "        #img2x = F.interpolate(img, scale_factor=1, mode='bilinear', align_corners=False)\n",
    "        #img4x = F.interpolate(img, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "\n",
    "        enc2x = self.tohr_enc2x.cuda()(enc2x)\n",
    "        img2x = F.interpolate(img, scale_factor=1/2, mode='bilinear', align_corners=False)\n",
    "        hr4x = self.conv_enc2x.cuda()(torch.cat((img2x, enc2x), dim=1))\n",
    "\n",
    "        enc4x = self.tohr_enc4x.cuda()(enc4x)\n",
    "        hr4x = self.conv_enc4x.cuda()(torch.cat((hr4x, enc4x), dim=1))\n",
    "\n",
    "        lr4x = F.interpolate(lr8x, scale_factor=1, mode='bilinear', align_corners=False)\n",
    "        img4x = F.interpolate(img, scale_factor=1/4, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        print(\"---\", hr4x.shape, lr4x.shape, img4x.shape)\n",
    "        \n",
    "        hr4x = self.conv_hr4x.cuda()(torch.cat((hr4x, lr4x, img4x), dim=1))\n",
    "\n",
    "        hr2x = F.interpolate(hr4x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        hr2x = self.conv_hr2x.cuda()(torch.cat((hr2x, enc2x), dim=1))\n",
    "\n",
    "        pred_detail = None\n",
    "        if not inference:\n",
    "            hr = F.interpolate(hr2x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            hr = self.conv_hr.cuda()(torch.cat((hr, img), dim=1))\n",
    "            pred_detail = torch.sigmoid(hr)\n",
    "\n",
    "        return pred_detail, hr2x\n",
    "    \n",
    "class FusionBranch(nn.Module):\n",
    "    \"\"\" Fusion Branch of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hr_channels, enc_channels):\n",
    "        super(FusionBranch, self).__init__()\n",
    "        self.conv_lr4x = Conv2dIBNormRelu(enc_channels[2], hr_channels, 5, stride=1, padding=2)\n",
    "        \n",
    "        self.conv_f2x = Conv2dIBNormRelu(2 * hr_channels, hr_channels, 3, stride=1, padding=1)\n",
    "        self.conv_f = nn.Sequential(\n",
    "            Conv2dIBNormRelu(hr_channels + 3, int(hr_channels / 2), 3, stride=1, padding=1),\n",
    "            Conv2dIBNormRelu(int(hr_channels / 2), 1, 1, stride=1, padding=0, with_ibn=False, with_relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, lr8x, hr2x):\n",
    "        lr4x = F.interpolate(lr8x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        lr4x = self.conv_lr4x.cuda()(lr4x)\n",
    "        lr2x = F.interpolate(lr4x, scale_factor=1, mode='bilinear', align_corners=False)\n",
    "\n",
    "        f2x = self.conv_f2x.cuda()(torch.cat((lr2x, hr2x), dim=1))\n",
    "        f = F.interpolate(f2x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        f = self.conv_f.cuda()(torch.cat((f, img), dim=1))\n",
    "        #pred_matte = torch.sigmoid(f)\n",
    "\n",
    "        #return pred_matte\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#  MODNet\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class MODNet(nn.Module):\n",
    "    \"\"\" Architecture of MODNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, hr_channels=32, backbone_arch='mobilenetv2', backbone_pretrained=True):\n",
    "        super(MODNet, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hr_channels = hr_channels\n",
    "        self.backbone_arch = backbone_arch \n",
    "        self.backbone_pretrained = backbone_pretrained\n",
    "\n",
    "        self.backbone = SUPPORTED_BACKBONES[self.backbone_arch](self.in_channels)\n",
    "\n",
    "        self.lr_branch = LRBranch(self.backbone)\n",
    "        self.hr_branch = HRBranch(self.hr_channels, self.backbone.enc_channels)\n",
    "        self.f_branch = FusionBranch(self.hr_channels, self.backbone.enc_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                self._init_conv(m)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
    "                self._init_norm(m)\n",
    "\n",
    "        if self.backbone_pretrained:\n",
    "            self.backbone.load_pretrained_ckpt()                \n",
    "\n",
    "    def forward(self, img, inference=False):\n",
    "        pred_semantic, lr8x, [enc2x, enc4x] = self.lr_branch(img, inference)\n",
    "        pred_detail, hr2x = self.hr_branch(img, enc2x, enc4x, lr8x, inference)\n",
    "        pred_matte = self.f_branch(img, lr8x, hr2x)\n",
    "\n",
    "        return pred_semantic, pred_detail, pred_matte\n",
    "    \n",
    "    def freeze_norm(self):\n",
    "        norm_types = [nn.BatchNorm2d, nn.InstanceNorm2d]\n",
    "        for m in self.modules():\n",
    "            for n in norm_types:\n",
    "                if isinstance(m, n):\n",
    "                    m.eval()\n",
    "                    continue\n",
    "\n",
    "    def _init_conv(self, conv):\n",
    "        nn.init.kaiming_uniform_(\n",
    "            conv.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        if conv.bias is not None:\n",
    "            nn.init.constant_(conv.bias, 0)\n",
    "\n",
    "    def _init_norm(self, norm):\n",
    "        if norm.weight is not None:\n",
    "            nn.init.constant_(norm.weight, 1)\n",
    "            nn.init.constant_(norm.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- [16, 24, 32, 96, 1280]\n",
      "--- torch.Size([2, 64, 56, 56]) torch.Size([2, 32, 56, 56]) torch.Size([2, 3, 56, 56])\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─LRBranch: 1-1                               [-1, 1, 28, 28]           --\n",
      "|    └─SEBlock: 2-1                           [-1, 96, 14, 14]          --\n",
      "|    |    └─AdaptiveAvgPool2d: 3-1            [-1, 96, 1, 1]            --\n",
      "|    |    └─Sequential: 3-2                   [-1, 96]                  4,608\n",
      "|    └─Conv2dIBNormRelu: 2-2                  [-1, 32, 28, 28]          --\n",
      "|    |    └─Sequential: 3-3                   [-1, 32, 28, 28]          76,864\n",
      "|    └─Conv2dIBNormRelu: 2-3                  [-1, 32, 56, 56]          --\n",
      "|    |    └─Sequential: 3-4                   [-1, 32, 56, 56]          25,664\n",
      "|    └─Conv2dIBNormRelu: 2-4                  [-1, 1, 28, 28]           --\n",
      "|    |    └─Sequential: 3-5                   [-1, 1, 28, 28]           289\n",
      "├─HRBranch: 1-2                               [-1, 1, 224, 224]         --\n",
      "|    └─Conv2dIBNormRelu: 2-5                  [-1, 32, 112, 112]        --\n",
      "|    |    └─Sequential: 3-6                   [-1, 32, 112, 112]        576\n",
      "|    └─Conv2dIBNormRelu: 2-6                  [-1, 32, 56, 56]          --\n",
      "|    |    └─Sequential: 3-7                   [-1, 32, 56, 56]          10,144\n",
      "|    └─Conv2dIBNormRelu: 2-7                  [-1, 32, 56, 56]          --\n",
      "|    |    └─Sequential: 3-8                   [-1, 32, 56, 56]          832\n",
      "|    └─Conv2dIBNormRelu: 2-8                  [-1, 64, 56, 56]          --\n",
      "|    |    └─Sequential: 3-9                   [-1, 64, 56, 56]          36,992\n",
      "|    └─Sequential: 2-9                        [-1, 32, 56, 56]          --\n",
      "|    |    └─Conv2dIBNormRelu: 3-10            [-1, 64, 56, 56]          57,152\n",
      "|    |    └─Conv2dIBNormRelu: 3-11            [-1, 64, 56, 56]          36,992\n",
      "|    |    └─Conv2dIBNormRelu: 3-12            [-1, 32, 56, 56]          18,496\n",
      "|    └─Sequential: 2-10                       [-1, 32, 112, 112]        --\n",
      "|    |    └─Conv2dIBNormRelu: 3-13            [-1, 64, 112, 112]        36,992\n",
      "|    |    └─Conv2dIBNormRelu: 3-14            [-1, 32, 112, 112]        18,496\n",
      "|    |    └─Conv2dIBNormRelu: 3-15            [-1, 32, 112, 112]        9,280\n",
      "|    |    └─Conv2dIBNormRelu: 3-16            [-1, 32, 112, 112]        9,280\n",
      "|    └─Sequential: 2-11                       [-1, 1, 224, 224]         --\n",
      "|    |    └─Conv2dIBNormRelu: 3-17            [-1, 32, 224, 224]        10,144\n",
      "|    |    └─Conv2dIBNormRelu: 3-18            [-1, 1, 224, 224]         33\n",
      "├─FusionBranch: 1-3                           [-1, 1, 224, 224]         --\n",
      "|    └─Conv2dIBNormRelu: 2-12                 [-1, 32, 112, 112]        --\n",
      "|    |    └─Sequential: 3-19                  [-1, 32, 112, 112]        25,664\n",
      "|    └─Conv2dIBNormRelu: 2-13                 [-1, 32, 112, 112]        --\n",
      "|    |    └─Sequential: 3-20                  [-1, 32, 112, 112]        18,496\n",
      "|    └─Sequential: 2-14                       [-1, 1, 224, 224]         --\n",
      "|    |    └─Conv2dIBNormRelu: 3-21            [-1, 16, 224, 224]        5,072\n",
      "|    |    └─Conv2dIBNormRelu: 3-22            [-1, 1, 224, 224]         17\n",
      "===============================================================================================\n",
      "Total params: 402,083\n",
      "Trainable params: 402,083\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 854.93\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 13.21\n",
      "Params size (MB): 1.53\n",
      "Estimated Total Size (MB): 15.32\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─LRBranch: 1-1                               [-1, 1, 28, 28]           --\n",
       "|    └─SEBlock: 2-1                           [-1, 96, 14, 14]          --\n",
       "|    |    └─AdaptiveAvgPool2d: 3-1            [-1, 96, 1, 1]            --\n",
       "|    |    └─Sequential: 3-2                   [-1, 96]                  4,608\n",
       "|    └─Conv2dIBNormRelu: 2-2                  [-1, 32, 28, 28]          --\n",
       "|    |    └─Sequential: 3-3                   [-1, 32, 28, 28]          76,864\n",
       "|    └─Conv2dIBNormRelu: 2-3                  [-1, 32, 56, 56]          --\n",
       "|    |    └─Sequential: 3-4                   [-1, 32, 56, 56]          25,664\n",
       "|    └─Conv2dIBNormRelu: 2-4                  [-1, 1, 28, 28]           --\n",
       "|    |    └─Sequential: 3-5                   [-1, 1, 28, 28]           289\n",
       "├─HRBranch: 1-2                               [-1, 1, 224, 224]         --\n",
       "|    └─Conv2dIBNormRelu: 2-5                  [-1, 32, 112, 112]        --\n",
       "|    |    └─Sequential: 3-6                   [-1, 32, 112, 112]        576\n",
       "|    └─Conv2dIBNormRelu: 2-6                  [-1, 32, 56, 56]          --\n",
       "|    |    └─Sequential: 3-7                   [-1, 32, 56, 56]          10,144\n",
       "|    └─Conv2dIBNormRelu: 2-7                  [-1, 32, 56, 56]          --\n",
       "|    |    └─Sequential: 3-8                   [-1, 32, 56, 56]          832\n",
       "|    └─Conv2dIBNormRelu: 2-8                  [-1, 64, 56, 56]          --\n",
       "|    |    └─Sequential: 3-9                   [-1, 64, 56, 56]          36,992\n",
       "|    └─Sequential: 2-9                        [-1, 32, 56, 56]          --\n",
       "|    |    └─Conv2dIBNormRelu: 3-10            [-1, 64, 56, 56]          57,152\n",
       "|    |    └─Conv2dIBNormRelu: 3-11            [-1, 64, 56, 56]          36,992\n",
       "|    |    └─Conv2dIBNormRelu: 3-12            [-1, 32, 56, 56]          18,496\n",
       "|    └─Sequential: 2-10                       [-1, 32, 112, 112]        --\n",
       "|    |    └─Conv2dIBNormRelu: 3-13            [-1, 64, 112, 112]        36,992\n",
       "|    |    └─Conv2dIBNormRelu: 3-14            [-1, 32, 112, 112]        18,496\n",
       "|    |    └─Conv2dIBNormRelu: 3-15            [-1, 32, 112, 112]        9,280\n",
       "|    |    └─Conv2dIBNormRelu: 3-16            [-1, 32, 112, 112]        9,280\n",
       "|    └─Sequential: 2-11                       [-1, 1, 224, 224]         --\n",
       "|    |    └─Conv2dIBNormRelu: 3-17            [-1, 32, 224, 224]        10,144\n",
       "|    |    └─Conv2dIBNormRelu: 3-18            [-1, 1, 224, 224]         33\n",
       "├─FusionBranch: 1-3                           [-1, 1, 224, 224]         --\n",
       "|    └─Conv2dIBNormRelu: 2-12                 [-1, 32, 112, 112]        --\n",
       "|    |    └─Sequential: 3-19                  [-1, 32, 112, 112]        25,664\n",
       "|    └─Conv2dIBNormRelu: 2-13                 [-1, 32, 112, 112]        --\n",
       "|    |    └─Sequential: 3-20                  [-1, 32, 112, 112]        18,496\n",
       "|    └─Sequential: 2-14                       [-1, 1, 224, 224]         --\n",
       "|    |    └─Conv2dIBNormRelu: 3-21            [-1, 16, 224, 224]        5,072\n",
       "|    |    └─Conv2dIBNormRelu: 3-22            [-1, 1, 224, 224]         17\n",
       "===============================================================================================\n",
       "Total params: 402,083\n",
       "Trainable params: 402,083\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 854.93\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 13.21\n",
       "Params size (MB): 1.53\n",
       "Estimated Total Size (MB): 15.32\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = MODNet()\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
